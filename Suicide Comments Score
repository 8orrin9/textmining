# Suicide Comments Score

## Import Package

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns



## Define Value

fname_comments = './drive/MyDrive/Colab Notebooks/DMS/data/suicide_comments.xlsx'
fname_scores = './drive/MyDrive/Colab Notebooks/DMS/data/suicide_scores.pkl'

df_c = pd.read_excel(fname_comments)
df_c



## Set Class KOTE from https://github.com/searle-j/KOTE.git

from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

model_name = 'searle-j/kote_for_easygoing_people'
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

pipe = TextClassificationPipeline(
        model=model,
        tokenizer=tokenizer,
        device=-1, # gpu number, use -1 if cpu used
        top_k=None,  # 상위 k개 클래스만 반환 설정 X
        function_to_apply='sigmoid'
    )



## Define Function: cut_test

from transformers import ElectraTokenizer

tokenizer = ElectraTokenizer.from_pretrained('beomi/KcELECTRA-base', revision = 'v2021')

def cut_text(text):
    MAX_LEN = 512
    tokens = tokenizer(text, return_tensors='pt')  # text를 PyTorch tensor 형태로 반환
    if tokens.input_ids.size(1) <= MAX_LEN:
        return text
        
    text_lst = []
    for ss in text.split():
        tokens = tokenizer(' '.join(text_lst + list(ss)), return_tensors='pt')
        if tokens.input_ids.size(1) > MAX_LEN:
            break
        text_lst.append(ss)
    return ' '.join(text_lst)



## Cut Comments - Max Length of Tokens: 512

df_c['comments'] = df_c['comments'].apply(cut_text)



## Get Scores by KOTE

%%time
scores = pipe(df_c['comments'].to_list())



## DataFramization

%%time
df_s = pd.DataFrame()
for idx, row in enumerate(scores):
    for dic in row:
        #df_s.loc[idx, dic['label']] = round(dic['score'],2)
        df_s.loc[idx, dic['label']] = dic['score']

df_r = pd.concat([df_c, df_s], axis = 1)
df_r



## Export

df_r.to_pickle(fname_scores)
